{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General\n",
    "\n",
    "## Dataset\n",
    "https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
    "\n",
    "# TODO:\n",
    "### David:\n",
    "- pre-processing\n",
    "  - feature scaling (standardize or normalize ?)\n",
    "- feature selection\n",
    "- performance visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for the final report.  What is the goal of our final project?\n",
    "\n",
    "Primary\n",
    "\n",
    "* Make RandomForestClassifier work and figure out how to optimize its predictive performance.\n",
    "* Show that it performs better than other algorithms.\n",
    "\n",
    "Secondary\n",
    "\n",
    "* Focus it more on understanding why an ML algorithm performs better\n",
    "* (Overfitting, high correlation, other pitfalls of ML algorithms)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports & Settings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# display all columns and rows:\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:orange'>NOTE</h1>\n",
    "\n",
    "### Breiman (2001) Section 5:\n",
    "\n",
    "* If, after feature selection, it is found that only a handful of features are actually any good, Breiman seems to suggest combining these features into some additional features for datasets with fewer than 3000 instances.  See paper for implementation.\n",
    "\n",
    "### Section 5.1:\n",
    "\n",
    "* Breiman on handling non-binary categorical variables when forming combined features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset & Preprocessing\n",
    "\n",
    "# Dataset\n",
    "df_original = pd.read_csv('dataset/telco-customer-churn.csv', index_col=0)\n",
    "df = df_original.copy()\n",
    "\n",
    "# Label Encoding (converting categorical to numerical)\n",
    "categorical_columns = [\n",
    "    'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines','InternetService',\n",
    "    'OnlineSecurity', 'OnlineBackup','DeviceProtection','TechSupport','StreamingTV',\n",
    "    'StreamingMovies','Contract','PaperlessBilling','PaymentMethod', 'Churn'\n",
    "]\n",
    "\n",
    "# convert and replace categorical columns with numerical data\n",
    "# encoding is done with categorical labels that sorted alphabetically so df = ['c','z','a'] will always encode to [1,2,0]\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "    df[col] = df[col].cat.codes\n",
    "\n",
    "# TotalCharges cleanup of blank columns ' ', will be replaced with 0\n",
    "df['TotalCharges'].replace(\" \", 0, inplace=True)\n",
    "df['TotalCharges'] = df['TotalCharges'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:orange'>NOTE</h1>\n",
    "\n",
    "### Breiman (2001) Section 9:\n",
    "\n",
    "* If the input dataset is just a combination of many \"weak\" (low-variance) features, a higher 'max_features' value will perform better so long as the features have low correlation.\n",
    "\n",
    "### Probst (2018) Section 2.3:\n",
    "\n",
    "The formula for Area Under the Curve of a Random Forest for binary classification (either 1 or 0) is:\n",
    "\n",
    "$AUC = \\frac{\\sum_{i=1}^{n_1} \\sum_{j=1}^{n_2} S(\\hat{p}_i^*,\\hat{p}_j^{**})}{n_1n_2}$\n",
    "\n",
    "* $n_1 =$ The number of observations whose class is predicted to be 1\n",
    "* $n_2 =$ The number of observations whose class is predicted to be 0\n",
    "* $\\hat{p}_{i}^*=$ The number of trees that predicted 1 for the $n_1^{th}$ instance divided by the number of trees in the forest\n",
    "* $\\hat{p}_{j}^{**}=$ The number of trees that predicted 1 for the $n_2^{th}$ instance divided by the number of trees in the forest\n",
    "\n",
    "$S(\\hat{p}_i^*,\\hat{p}_j^{**}) =$ A function that returns the following:\n",
    "\n",
    "* If $(\\hat{p}_i^* < \\hat{p}_j^{**})$, return 0.0\n",
    "* If $(\\hat{p}_i^* = \\hat{p}_j^{**})$, return 0.5\n",
    "* If $(\\hat{p}_i^* > \\hat{p}_j^{**})$, return 1.0\n",
    "\n",
    "The larger this value, the better the classifier is.\n",
    "\n",
    "Unsure if this is what's implemented by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "\n",
    "class RFC:\n",
    "    '''\n",
    "    Parameters:\n",
    "      * X = A pandas.DataFrame of features\n",
    "      * y = An associative (same index as X) pandas.Series of labels\n",
    "      * hyperParameters = A dict whose keys correspond to the parameters of\n",
    "        RandomForestClassifer and whose values are lists of arguments for those\n",
    "        parameters\n",
    "      * refit = The name of the sklearn.metrics scoring function to use to\n",
    "        ultimately rank classifiers:\n",
    "          - 'auc' = roc_auc_score\n",
    "          - 'brier' = brier_score_loss\n",
    "          - 'accuracy' = accuracy_score\n",
    "      * cvFolds = The number of k-folds to use in cross-validation\n",
    "    Other notes:\n",
    "      * Research paper references throughout this class are done in this manner:\n",
    "         - Breiman (2001) = B\n",
    "         - Probst  (2008) = P\n",
    "        Section and subsection numbers will be added after these aliases like\n",
    "        B2.1 to show that a comment refers to Breiman (2001) Section 2 Subsection 1\n",
    "    '''\n",
    "    def __init__(self, X, y, hyperParameters={}, refit='auc', cvFolds=5):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        hyperParams = \\\n",
    "            self.__getDefaultParams__() if len(hyperParameters) == 0 else self.__validateParams__(hyperParameters)\n",
    "        self.clf = self.__setupGrid__(refit, hyperParams, cvFolds)\n",
    "        \n",
    "    def fit(self):\n",
    "        self.clf.fit(self.X, self.y)\n",
    "    \n",
    "    def __setupGrid__(self, refit, hyperParams, folds):\n",
    "        ''' Sets up and returns a GridSearchCV object to tune the parameters\n",
    "            of a RandomForestClassifier\n",
    "        '''\n",
    "        VALID = ['auc', 'brier', 'accuracy']\n",
    "        if not refit in VALID:\n",
    "            raise ValueError(\"refit must equal one of these three values: 'auc', 'brier', or 'accuracy'\")\n",
    "        ''' P5.1\n",
    "            Suggests AUC, Brier, and Log Loss(for regression) are all better metrics to judge\n",
    "            convergence on than the accuracy.\n",
    "        '''\n",
    "        scoring = {\n",
    "            'auc': skm.make_scorer(skm.roc_auc_score, needs_threshold=True),\n",
    "            'brier': skm.make_scorer(skm.brier_score_loss, greater_is_better=False, needs_proba=True, pos_label=1),\n",
    "            'accuracy': skm.make_scorer(skm.accuracy_score)}\n",
    "        return GridSearchCV(\n",
    "            RandomForestClassifier(),\n",
    "            param_grid = hyperParams,\n",
    "            scoring = scoring,\n",
    "            n_jobs = -1,\n",
    "            refit = refit,\n",
    "            cv = folds,\n",
    "            verbose = 3,\n",
    "            pre_dispatch = 4,\n",
    "            return_train_score = True)\n",
    "    \n",
    "    def __getDefaultParams__(self):\n",
    "        ''' Supplies default parameters to test based on what our source papers\n",
    "            suggest are generally good.\n",
    "        '''\n",
    "        out = {}\n",
    "        ''' B4\n",
    "            Suggests selecting more than 1 features to split a node with\n",
    "            doesn't perform any better than selecting 1 so long as we have a high\n",
    "            number of trees.\n",
    "            \n",
    "            sklearn sets its default 'max_features'='sqrt', so this is added as one of\n",
    "            our defaults to investigate why.  Did they find that 'sqrt' performs better\n",
    "            than Breiman's suggested 1?\n",
    "        '''\n",
    "        out['max_features'] = [1, 'sqrt']\n",
    "        ''' P5.3\n",
    "            Suggests that the biggest performance gain is experienced by the first 100\n",
    "            trees.  However, lower 'max_samples' values, lower 'max_depth' values, and\n",
    "            higher 'max_features' values reduce inter-tree correlation and therefore\n",
    "            increase the number of trees needed to reach convergence.\n",
    "        '''\n",
    "        out['max_depth'] = [None, 3]\n",
    "        out['n_estimators'] = [100, 200]\n",
    "        ''' B3\n",
    "            Suggests each bootstrap sample should ideally have 2/3s of N, the length of X.\n",
    "        '''\n",
    "        out['max_samples'] = [float(2/3)]\n",
    "        \n",
    "        out['oob_score'] = [True]\n",
    "        out['n_jobs'] = [-1]\n",
    "        return out\n",
    "\n",
    "    def __validateParams__(self, params):\n",
    "        ''' Removes any misspelled or non-existent-in-RandomForestClassifier\n",
    "            parameter name keys from the dict passed in by the caller.\n",
    "        '''\n",
    "        VALID = ['n_estimators', 'criterion', 'max_depth', 'min_samples_split',\n",
    "                 'min_samples_leaf', 'min_weight_fraction_leaf', 'max_features',\n",
    "                 'max_leaf_nodes', 'min_impurity_decrease', 'boostrap',\n",
    "                 'oob_score','n_jobs', 'random_state', 'verbose', 'warm_start',\n",
    "                 'class_weight', 'ccp_alpha', 'max_samples']\n",
    "        invalidKeys = []\n",
    "        for key in params:\n",
    "            if key not in valid:\n",
    "                params.pop(key)\n",
    "                invalidKeys += [key]\n",
    "        if len(invalidKeys) > 0:\n",
    "            print(\"These are not valid RandomForestClassifier parameter names: {}\\n\".format(invalidKeys) + \\\n",
    "                  \"They will not be tuned by GridSearchCV\")\n",
    "        return params if len(params) > 0 else self.__getDefaultParams__()\n",
    "    \n",
    "\n",
    "## Testing\n",
    "## TODO: Define some methods that calculate and display the different measures of convergence (Accuracy, AUC, ROC)\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]\n",
    "rfc = RFC(X, y)\n",
    "rfc.fit()\n",
    "print(rfc.clf.best_estimator_)\n",
    "pd.DataFrame.from_dict(rfc.clf.cv_results_).loc[:, ['params','rank_test_auc', 'rank_test_brier', 'rank_test_accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics\n",
    "\n",
    "# Confusion Matrix\n",
    "cf = skm.confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cf/np.sum(cf), fmt='.2%', annot=True, cmap='Blues')\n",
    "\n",
    "# Classification Report\n",
    "print(skm.classification_report(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
