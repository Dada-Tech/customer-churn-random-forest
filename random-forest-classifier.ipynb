{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General\n",
    "\n",
    "## Dataset\n",
    "https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
    "\n",
    "# TODO:\n",
    "### David:\n",
    "- pre-processing\n",
    "  - Compute average for TotalColumns & fill in\n",
    "  - feature scaling (standardize or normalize ?)\n",
    "  - mapping\n",
    "  - export processed csv to Tim\n",
    "- feature selection\n",
    "- performance visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for the final report.  What is the goal of our final project?\n",
    "\n",
    "Primary\n",
    "\n",
    "* Make RandomForestClassifier work and figure out how to optimize its predictive performance.\n",
    "* Show that it performs better than other algorithms.\n",
    "\n",
    "Secondary\n",
    "\n",
    "* Focus it more on understanding why an ML algorithm performs better\n",
    "* (Overfitting, high correlation, other pitfalls of ML algorithms)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports & Settings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# display all columns and rows:\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:orange'>NOTE</h1>\n",
    "\n",
    "### Breiman (2001) Section 5:\n",
    "\n",
    "* If, after feature selection, it is found that only a handful of features are actually any good, Breiman seems to suggest combining these features into some additional features for datasets with fewer than 3000 instances.  See paper for implementation.\n",
    "\n",
    "### Section 5.1:\n",
    "\n",
    "* Breiman on handling non-binary categorical variables when forming combined features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset & Preprocessing\n",
    "\n",
    "# Dataset\n",
    "df_original = pd.read_csv('dataset/telco-customer-churn.csv', index_col=0)\n",
    "df = df_original.copy()\n",
    "\n",
    "# Label Encoding (converting categorical to numerical)\n",
    "categorical_columns = [\n",
    "    'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines','InternetService',\n",
    "    'OnlineSecurity', 'OnlineBackup','DeviceProtection','TechSupport','StreamingTV',\n",
    "    'StreamingMovies','Contract','PaperlessBilling','PaymentMethod', 'Churn'\n",
    "]\n",
    "\n",
    "# convert and replace categorical columns with numerical data\n",
    "# encoding is done with categorical labels that sorted alphabetically so df = ['c','z','a'] will always encode to [1,2,0]\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "    df[col] = df[col].cat.codes\n",
    "\n",
    "# Dataframe where rows with blank TotalCharges ' ' replaced with 0\n",
    "df_0 = df.copy()\n",
    "df_0['TotalCharges'].replace(\" \", 0, inplace=True)\n",
    "df_0['TotalCharges'] = df_0['TotalCharges'].astype(float)\n",
    "\n",
    "# Dataframe where rows with blank TotalCharges ' ' are deleted\n",
    "df_d = df.copy()\n",
    "df_d.drop(df_d[df_d.TotalCharges == \" \"].index, inplace=True)\n",
    "df_d['TotalCharges'] = df_d['TotalCharges'].astype(float)\n",
    "\n",
    "\n",
    "total_charges_mean = (df_d['TotalCharges'].mean())\n",
    "\n",
    "# Dataframe where rows with blank TotalCharges ' ' are replaced by the mean of TotalCharges column\n",
    "df_m = df.copy()\n",
    "df_m['TotalCharges'].replace(\" \", total_charges_mean, inplace=True)\n",
    "df_m['TotalCharges'] = df_m['TotalCharges'].astype(float)\n",
    "\n",
    "# Set df to use one of the preprocessed sets\n",
    "df = df_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:orange'>NOTE</h1>\n",
    "\n",
    "### Breiman (2001) Section 9:\n",
    "\n",
    "* If the input dataset is just a combination of many \"weak\" (low-variance) features, a higher 'max_features' value will perform better so long as the features have low correlation.\n",
    "\n",
    "### Probst (2018) Section 2.3:\n",
    "\n",
    "The formula for Area Under the Curve of a Random Forest for binary classification (either 1 or 0) is:\n",
    "\n",
    "$AUC = \\frac{\\sum_{i=1}^{n_1} \\sum_{j=1}^{n_2} S(\\hat{p}_i^*,\\hat{p}_j^{**})}{n_1n_2}$\n",
    "\n",
    "* $n_1 =$ The number of observations whose class is predicted to be 1\n",
    "* $n_2 =$ The number of observations whose class is predicted to be 0\n",
    "* $\\hat{p}_{i}^*=$ The number of trees that predicted 1 for the $n_1^{th}$ instance divided by the number of trees in the forest\n",
    "* $\\hat{p}_{j}^{**}=$ The number of trees that predicted 1 for the $n_2^{th}$ instance divided by the number of trees in the forest\n",
    "\n",
    "$S(\\hat{p}_i^*,\\hat{p}_j^{**}) =$ A function that returns the following:\n",
    "\n",
    "* If $(\\hat{p}_i^* < \\hat{p}_j^{**})$, return 0.0\n",
    "* If $(\\hat{p}_i^* = \\hat{p}_j^{**})$, return 0.5\n",
    "* If $(\\hat{p}_i^* > \\hat{p}_j^{**})$, return 1.0\n",
    "\n",
    "The larger this value, the better the classifier is.\n",
    "\n",
    "Unsure if this is what's implemented by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                       max_samples=0.6666666666666666, n_estimators=200,\n",
      "                       n_jobs=-1, oob_score=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                              params  rank_test_auc  \\\n0  {'max_depth': None, 'max_features': 1, 'max_sa...              8   \n1  {'max_depth': None, 'max_features': 1, 'max_sa...              7   \n2  {'max_depth': None, 'max_features': 'sqrt', 'm...              6   \n3  {'max_depth': None, 'max_features': 'sqrt', 'm...              4   \n4  {'max_depth': 3, 'max_features': 1, 'max_sampl...              5   \n5  {'max_depth': 3, 'max_features': 1, 'max_sampl...              3   \n6  {'max_depth': 3, 'max_features': 'sqrt', 'max_...              2   \n7  {'max_depth': 3, 'max_features': 'sqrt', 'max_...              1   \n\n   rank_test_brier  rank_test_accuracy  \n0                4                   1  \n1                3                   3  \n2                2                   4  \n3                1                   5  \n4                8                   7  \n5                7                   8  \n6                5                   2  \n7                6                   6  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>rank_test_auc</th>\n      <th>rank_test_brier</th>\n      <th>rank_test_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'max_depth': None, 'max_features': 1, 'max_sa...</td>\n      <td>8</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'max_depth': None, 'max_features': 1, 'max_sa...</td>\n      <td>7</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'max_depth': None, 'max_features': 'sqrt', 'm...</td>\n      <td>6</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'max_depth': None, 'max_features': 'sqrt', 'm...</td>\n      <td>4</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'max_depth': 3, 'max_features': 1, 'max_sampl...</td>\n      <td>5</td>\n      <td>8</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{'max_depth': 3, 'max_features': 1, 'max_sampl...</td>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>{'max_depth': 3, 'max_features': 'sqrt', 'max_...</td>\n      <td>2</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>{'max_depth': 3, 'max_features': 'sqrt', 'max_...</td>\n      <td>1</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Model\n",
    "## TODO: Define some methods that calculate and display the different measures of convergence (Accuracy, AUC, ROC)\n",
    "\n",
    "class RFC:\n",
    "    '''\n",
    "    Parameters:\n",
    "      * X = A pandas.DataFrame of features\n",
    "      * y = An associative (same index as X) pandas.Series of labels\n",
    "      * hyperParameters = A dict whose keys correspond to the parameters of\n",
    "        RandomForestClassifer and whose values are lists of arguments for those\n",
    "        parameters\n",
    "      * refit = The name of the sklearn.metrics scoring function to use to\n",
    "        ultimately rank classifiers:\n",
    "          - 'auc' = roc_auc_score\n",
    "          - 'brier' = brier_score_loss\n",
    "          - 'accuracy' = accuracy_score\n",
    "      * cvFolds = The number of k-folds to use in cross-validation\n",
    "    Other notes:\n",
    "      * Research paper references throughout this class are done in this manner:\n",
    "         - Breiman (2001) = B\n",
    "         - Probst  (2018) = P\n",
    "        Section and subsection numbers will be added after these aliases like\n",
    "        B2.1 to show that a comment refers to Breiman (2001) Section 2 Subsection 1\n",
    "    '''\n",
    "    def __init__(self, X, y, hyperParameters={}, refit='auc', cvFolds=5):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        hyperParams = \\\n",
    "            self.__getDefaultParams__() if len(hyperParameters) == 0 else self.__validateParams__(hyperParameters)\n",
    "        self.clf = self.__setupGrid__(refit, hyperParams, cvFolds)\n",
    "        \n",
    "    def fit(self):\n",
    "        self.clf.fit(self.X, self.y)\n",
    "    \n",
    "    def __setupGrid__(self, refit, hyperParams, folds):\n",
    "        ''' Sets up and returns a GridSearchCV object to tune the parameters\n",
    "            of a RandomForestClassifier\n",
    "        '''\n",
    "        VALID = ['auc', 'brier', 'accuracy']\n",
    "        if not refit in VALID:\n",
    "            raise ValueError(\"refit must equal one of these three values: 'auc', 'brier', or 'accuracy'\")\n",
    "        ''' P5.1\n",
    "            Suggests AUC, Brier, and Log Loss(for regression) are all better metrics to judge\n",
    "            convergence on than the accuracy.\n",
    "        '''\n",
    "        scoring = {\n",
    "            'auc': skm.make_scorer(skm.roc_auc_score, needs_threshold=True),\n",
    "            'brier': skm.make_scorer(skm.brier_score_loss, greater_is_better=False, needs_proba=True, pos_label=1),\n",
    "            'accuracy': skm.make_scorer(skm.accuracy_score)}\n",
    "        return GridSearchCV(\n",
    "            RandomForestClassifier(),\n",
    "            param_grid = hyperParams,\n",
    "            scoring = scoring,\n",
    "            n_jobs = -1,\n",
    "            refit = refit,\n",
    "            cv = folds,\n",
    "            verbose = 3,\n",
    "            pre_dispatch = 4,\n",
    "            return_train_score = True)\n",
    "    \n",
    "    def __getDefaultParams__(self):\n",
    "        ''' Supplies default parameters to test based on what our source papers\n",
    "            suggest are generally good.\n",
    "        '''\n",
    "        out = {}\n",
    "        ''' B4\n",
    "            Suggests selecting more than 1 features to split a node with\n",
    "            doesn't perform any better than selecting 1 so long as we have a high\n",
    "            number of trees.\n",
    "            \n",
    "            sklearn sets its default 'max_features'='sqrt', so this is added as one of\n",
    "            our defaults to investigate why.  Did they find that 'sqrt' performs better\n",
    "            than Breiman's suggested 1?\n",
    "        '''\n",
    "        out['max_features'] = [1, 'sqrt']\n",
    "        ''' P5.3\n",
    "            Suggests that the biggest performance gain is experienced by the first 100\n",
    "            trees.  However, lower 'max_samples' values, lower 'max_depth' values, and\n",
    "            higher 'max_features' values reduce inter-tree correlation and therefore\n",
    "            increase the number of trees needed to reach convergence.\n",
    "        '''\n",
    "        out['max_depth'] = [None, 3]\n",
    "        out['n_estimators'] = [100, 200]\n",
    "        ''' B3\n",
    "            Suggests each bootstrap sample should ideally have 2/3s of N, the length of X.\n",
    "        '''\n",
    "        out['max_samples'] = [float(2/3)]\n",
    "        \n",
    "        out['oob_score'] = [True]\n",
    "        out['n_jobs'] = [-1]\n",
    "        return out\n",
    "\n",
    "    def __validateParams__(self, params):\n",
    "        ''' Removes any misspelled or non-existent-in-RandomForestClassifier\n",
    "            parameter name keys from the dict passed in by the caller.\n",
    "        '''\n",
    "        VALID = ['n_estimators', 'criterion', 'max_depth', 'min_samples_split',\n",
    "                 'min_samples_leaf', 'min_weight_fraction_leaf', 'max_features',\n",
    "                 'max_leaf_nodes', 'min_impurity_decrease', 'boostrap',\n",
    "                 'oob_score','n_jobs', 'random_state', 'verbose', 'warm_start',\n",
    "                 'class_weight', 'ccp_alpha', 'max_samples']\n",
    "        invalidKeys = []\n",
    "        for key in params:\n",
    "            if key not in valid:\n",
    "                params.pop(key)\n",
    "                invalidKeys += [key]\n",
    "        if len(invalidKeys) > 0:\n",
    "            print(\"These are not valid RandomForestClassifier parameter names: {}\\n\".format(invalidKeys) + \\\n",
    "                  \"They will not be tuned by GridSearchCV\")\n",
    "        return params if len(params) > 0 else self.__getDefaultParams__()\n",
    "    \n",
    "\n",
    "## Testing\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]\n",
    "rfc = RFC(X, y)\n",
    "rfc.fit()\n",
    "print(rfc.clf.best_estimator_)\n",
    "pd.DataFrame.from_dict(rfc.clf.cv_results_).loc[:, ['params','rank_test_auc', 'rank_test_brier', 'rank_test_accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m## Metrics\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Confusion Matrix\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m cf \u001B[38;5;241m=\u001B[39m skm\u001B[38;5;241m.\u001B[39mconfusion_matrix(\u001B[43my_pred\u001B[49m,y_test)\n\u001B[1;32m      5\u001B[0m sns\u001B[38;5;241m.\u001B[39mheatmap(cf\u001B[38;5;241m/\u001B[39mnp\u001B[38;5;241m.\u001B[39msum(cf), fmt\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.2\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m'\u001B[39m, annot\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBlues\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Classification Report\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "## Metrics\n",
    "\n",
    "# Confusion Matrix\n",
    "cf = skm.confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cf/np.sum(cf), fmt='.2%', annot=True, cmap='Blues')\n",
    "\n",
    "# Classification Report\n",
    "print(skm.classification_report(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
